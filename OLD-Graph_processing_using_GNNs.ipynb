{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003ad806",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4b2453",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87e8141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import networkx as nx\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "# featuretools for automated feature engineering\n",
    "import featuretools as ft\n",
    "\n",
    "# matplotlit and seaborn for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 22\n",
    "import seaborn as sns\n",
    "import bqplot as bq\n",
    "\n",
    "# Suppress warnings from pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# modeling \n",
    "import lightgbm as lgb\n",
    "\n",
    "# utilities\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, accuracy_score, auc, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# memory management\n",
    "import gc\n",
    "\n",
    "# import EarlyStopping\n",
    "# from pytorchtools import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1cf81c",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5701f673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows:  103\n",
      "Number of columns:  7797\n"
     ]
    }
   ],
   "source": [
    "# read a .csv file as pd.DataFrame\n",
    "df = pd.read_csv('./data/Data - Processed.csv')\n",
    "df_columns = df.columns.tolist()\n",
    "print('Number of rows: ', df.shape[0])\n",
    "print('Number of columns: ', df.shape[1])\n",
    "# print('Columns: ', df_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f78d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of categorical features:  30\n",
      "Number of numerical features:  7767\n"
     ]
    }
   ],
   "source": [
    "# count categorical features and numerical features\n",
    "categorical_features = [col for col in df_columns if df[col].dtype == 'object']\n",
    "numerical_features = [col for col in df_columns if df[col].dtype != 'object']\n",
    "print('Number of categorical features: ', len(categorical_features))\n",
    "print('Number of numerical features: ', len(numerical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f58649",
   "metadata": {},
   "source": [
    "### Remove feature having low variance (<0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ae16d26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year_of_Diagnosis  Tumor_Sequence_Number  Age_At_Diagnosis  \\\n",
      "0               2008                      0                64   \n",
      "1               1998                      0                69   \n",
      "2               1998                      0                66   \n",
      "3               2004                      0                72   \n",
      "4               2009                      0                52   \n",
      "\n",
      "   Regional_Lymph_Nodes_examined  Regional_Lymph_Nodes_positive  \\\n",
      "0                             11                              0   \n",
      "1                             12                              0   \n",
      "2                             10                              0   \n",
      "3                             25                              0   \n",
      "4                             18                              0   \n",
      "\n",
      "   Year_of_Last_Contact_or_Death__S  Year_of_Last_Contact_or_Death__F  \\\n",
      "0                              2015                              2015   \n",
      "1                              1999                              1999   \n",
      "2                              2015                              2015   \n",
      "3                              2012                              2012   \n",
      "4                              2015                              2015   \n",
      "\n",
      "   Overall_Survival_1__Days_  Overall_Survival_1__Months_  \\\n",
      "0                       2740                           90   \n",
      "1                        459                           15   \n",
      "2                       6230                          204   \n",
      "3                       2825                           92   \n",
      "4                       2537                           83   \n",
      "\n",
      "   Overall_Survival_2__Days_  ...       8306       8307       8308       8309  \\\n",
      "0                       2599  ...  16.627917  16.734554  16.697517  16.994888   \n",
      "1                        428  ...  16.830417   0.000000  16.642156  17.010478   \n",
      "2                       6170  ...  16.639782   0.000000  16.225933  16.298286   \n",
      "3                       2825  ...  16.702006   0.000000  16.240624  17.246538   \n",
      "4                       2516  ...  16.733236   0.000000  15.757718   0.000000   \n",
      "\n",
      "        8310  8311       8312       8314       8315       8316  \n",
      "0  17.356033   0.0  16.540088  16.824544  16.601595  17.183535  \n",
      "1  17.284266   0.0  18.409225  16.649383  16.570425  17.183928  \n",
      "2   0.000000   0.0  16.768196  16.684280  16.369291  17.068271  \n",
      "3  17.321641   0.0  17.038372  16.672531  16.549712  17.190188  \n",
      "4  17.170831   0.0  16.161420  16.750601  16.513946  16.624117  \n",
      "\n",
      "[5 rows x 7767 columns]\n"
     ]
    }
   ],
   "source": [
    "# select the columns having numerical values\n",
    "df_numerical_features = df[numerical_features]\n",
    "print(df_numerical_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ec4fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sample_name Gender__Cancer_Registry_ Ethnicity__Cancer_Registry_  \\\n",
      "0      SCC001                   FEMALE                 NON-SPANISH   \n",
      "1      SCC002                     MALE                 NON-SPANISH   \n",
      "2      SCC003                     MALE                 NON-SPANISH   \n",
      "3      SCC004                     MALE                 NON-SPANISH   \n",
      "4      SCC005                     MALE                 NON-SPANISH   \n",
      "\n",
      "  Race__Cancer_Registry_1_ Grade_Differentiation  \\\n",
      "0                    WHITE  MODERATELY DIFFEREN.   \n",
      "1                    WHITE      POORLY DIFFEREN.   \n",
      "2                    WHITE      POORLY DIFFEREN.   \n",
      "3                    WHITE      POORLY DIFFEREN.   \n",
      "4                    WHITE      POORLY DIFFEREN.   \n",
      "\n",
      "                           Histology Laterality  \\\n",
      "0  80703 SQUAMOUS CELL CARCINOMA NOS      RIGHT   \n",
      "1  80703 SQUAMOUS CELL CARCINOMA NOS       LEFT   \n",
      "2  80703 SQUAMOUS CELL CARCINOMA NOS      RIGHT   \n",
      "3  80703 SQUAMOUS CELL CARCINOMA NOS      RIGHT   \n",
      "4  80703 SQUAMOUS CELL CARCINOMA NOS       LEFT   \n",
      "\n",
      "  Summary_of_Treatment__1st_course Surgery_Radiation_Sequence  \\\n",
      "0                          SURGERY                   NOT APPL   \n",
      "1                          SURGERY                   NOT APPL   \n",
      "2                          SURGERY                   NOT APPL   \n",
      "3                        SURG/CHEM                   NOT APPL   \n",
      "4                          SURGERY                   NOT APPL   \n",
      "\n",
      "  Pathological_TNM__T  ... subtype.1  \\\n",
      "0                 P2A  ...  Inflamed   \n",
      "1                 P1B  ...  Inflamed   \n",
      "2                 P1B  ...  Inflamed   \n",
      "3                 P2A  ...  Inflamed   \n",
      "4                 P2B  ...  Inflamed   \n",
      "\n",
      "  Tobacco use (FCDS) [Data element retired in 2011]  \\\n",
      "0                                MODERATE (1-2 PPD)   \n",
      "1                                              HIST   \n",
      "2                                              HIST   \n",
      "3                                              NONE   \n",
      "4                                              HIST   \n",
      "\n",
      "  Recently Reported Cigarette Smoking Status Recently Reported Tobacco Use  \\\n",
      "0                                       EVER                          EVER   \n",
      "1                                       EVER                          EVER   \n",
      "2                                       EVER                          EVER   \n",
      "3                                       EVER                          EVER   \n",
      "4                                       EVER                          EVER   \n",
      "\n",
      "  Trypsin.lot.number Digestion.Start.Time Digestion.End.Time TMT.Sample.Name  \\\n",
      "0           R5E15825              2:34 PM           11:35 AM   TMT26_TMT-130   \n",
      "1           R5E15825              1:00 PM           11:25 AM   TMT23_TMT-131   \n",
      "2           R5E15825              1:00 PM           11:25 AM   TMT24_TMT-128   \n",
      "3           R5E15825              1:00 PM           11:25 AM   TMT23_TMT-127   \n",
      "4           R5E15825              1:54 PM           11:12 AM   TMT10_TMT-127   \n",
      "\n",
      "  Proteomic Subtype Wilkerson Classification  \n",
      "0        Inflamed A                classical  \n",
      "1        Inflamed A                secretory  \n",
      "2        Inflamed A                secretory  \n",
      "3        Inflamed A                primitive  \n",
      "4        Inflamed A                classical  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# select the columns having categorical values\n",
    "df_categorical_features = df[categorical_features]\n",
    "print(df_categorical_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4761baff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes data and returns it after removing the features\n",
    "# having less than the given threshold variance\n",
    "\n",
    "def variance_threshold_selector(data, threshold=0.9):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    selector.fit(data)\n",
    "    return data[data.columns[selector.get_support(indices=True)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c742c4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(103, 4477)\n"
     ]
    }
   ],
   "source": [
    "x = variance_threshold_selector(df_numerical_features, 0.25)\n",
    "print(type(x))\n",
    "print(x.shape)\n",
    "x_columns = x.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c4182d",
   "metadata": {},
   "source": [
    "### Removing colinear features, high correlations (>75%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "646f96d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4477, 4477)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Diagnosis</th>\n",
       "      <th>Tumor_Sequence_Number</th>\n",
       "      <th>Age_At_Diagnosis</th>\n",
       "      <th>Regional_Lymph_Nodes_examined</th>\n",
       "      <th>Regional_Lymph_Nodes_positive</th>\n",
       "      <th>Year_of_Last_Contact_or_Death__S</th>\n",
       "      <th>Year_of_Last_Contact_or_Death__F</th>\n",
       "      <th>Overall_Survival_1__Days_</th>\n",
       "      <th>Overall_Survival_1__Months_</th>\n",
       "      <th>Overall_Survival_2__Days_</th>\n",
       "      <th>...</th>\n",
       "      <th>8300</th>\n",
       "      <th>8301</th>\n",
       "      <th>8304</th>\n",
       "      <th>8305</th>\n",
       "      <th>8307</th>\n",
       "      <th>8309</th>\n",
       "      <th>8310</th>\n",
       "      <th>8311</th>\n",
       "      <th>8314</th>\n",
       "      <th>8316</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year_of_Diagnosis</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100609</td>\n",
       "      <td>0.074038</td>\n",
       "      <td>0.052394</td>\n",
       "      <td>0.116608</td>\n",
       "      <td>0.662213</td>\n",
       "      <td>0.656449</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.283572</td>\n",
       "      <td>0.285061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>0.024911</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>0.051857</td>\n",
       "      <td>0.170086</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.049978</td>\n",
       "      <td>0.072603</td>\n",
       "      <td>0.090380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tumor_Sequence_Number</th>\n",
       "      <td>0.100609</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.265371</td>\n",
       "      <td>0.197846</td>\n",
       "      <td>0.096182</td>\n",
       "      <td>0.114551</td>\n",
       "      <td>0.127843</td>\n",
       "      <td>0.044502</td>\n",
       "      <td>0.044990</td>\n",
       "      <td>0.046955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020590</td>\n",
       "      <td>0.039268</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.044364</td>\n",
       "      <td>0.073432</td>\n",
       "      <td>0.068132</td>\n",
       "      <td>0.060961</td>\n",
       "      <td>0.075107</td>\n",
       "      <td>0.110043</td>\n",
       "      <td>0.062217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_At_Diagnosis</th>\n",
       "      <td>0.074038</td>\n",
       "      <td>0.265371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024481</td>\n",
       "      <td>0.083128</td>\n",
       "      <td>0.089446</td>\n",
       "      <td>0.082757</td>\n",
       "      <td>0.204286</td>\n",
       "      <td>0.204993</td>\n",
       "      <td>0.202093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105379</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.017555</td>\n",
       "      <td>0.027586</td>\n",
       "      <td>0.030560</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>0.134809</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.107989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regional_Lymph_Nodes_examined</th>\n",
       "      <td>0.052394</td>\n",
       "      <td>0.197846</td>\n",
       "      <td>0.024481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214147</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.105154</td>\n",
       "      <td>0.204488</td>\n",
       "      <td>0.203869</td>\n",
       "      <td>0.202699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162477</td>\n",
       "      <td>0.144585</td>\n",
       "      <td>0.068971</td>\n",
       "      <td>0.095920</td>\n",
       "      <td>0.075105</td>\n",
       "      <td>0.026212</td>\n",
       "      <td>0.079932</td>\n",
       "      <td>0.013017</td>\n",
       "      <td>0.076088</td>\n",
       "      <td>0.032443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regional_Lymph_Nodes_positive</th>\n",
       "      <td>0.116608</td>\n",
       "      <td>0.096182</td>\n",
       "      <td>0.083128</td>\n",
       "      <td>0.214147</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014539</td>\n",
       "      <td>0.015377</td>\n",
       "      <td>0.165666</td>\n",
       "      <td>0.164628</td>\n",
       "      <td>0.164375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126528</td>\n",
       "      <td>0.052517</td>\n",
       "      <td>0.043171</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.122362</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>0.049116</td>\n",
       "      <td>0.109744</td>\n",
       "      <td>0.073299</td>\n",
       "      <td>0.080292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Year_of_Diagnosis  Tumor_Sequence_Number  \\\n",
       "Year_of_Diagnosis                       1.000000               0.100609   \n",
       "Tumor_Sequence_Number                   0.100609               1.000000   \n",
       "Age_At_Diagnosis                        0.074038               0.265371   \n",
       "Regional_Lymph_Nodes_examined           0.052394               0.197846   \n",
       "Regional_Lymph_Nodes_positive           0.116608               0.096182   \n",
       "\n",
       "                               Age_At_Diagnosis  \\\n",
       "Year_of_Diagnosis                      0.074038   \n",
       "Tumor_Sequence_Number                  0.265371   \n",
       "Age_At_Diagnosis                       1.000000   \n",
       "Regional_Lymph_Nodes_examined          0.024481   \n",
       "Regional_Lymph_Nodes_positive          0.083128   \n",
       "\n",
       "                               Regional_Lymph_Nodes_examined  \\\n",
       "Year_of_Diagnosis                                   0.052394   \n",
       "Tumor_Sequence_Number                               0.197846   \n",
       "Age_At_Diagnosis                                    0.024481   \n",
       "Regional_Lymph_Nodes_examined                       1.000000   \n",
       "Regional_Lymph_Nodes_positive                       0.214147   \n",
       "\n",
       "                               Regional_Lymph_Nodes_positive  \\\n",
       "Year_of_Diagnosis                                   0.116608   \n",
       "Tumor_Sequence_Number                               0.096182   \n",
       "Age_At_Diagnosis                                    0.083128   \n",
       "Regional_Lymph_Nodes_examined                       0.214147   \n",
       "Regional_Lymph_Nodes_positive                       1.000000   \n",
       "\n",
       "                               Year_of_Last_Contact_or_Death__S  \\\n",
       "Year_of_Diagnosis                                      0.662213   \n",
       "Tumor_Sequence_Number                                  0.114551   \n",
       "Age_At_Diagnosis                                       0.089446   \n",
       "Regional_Lymph_Nodes_examined                          0.106061   \n",
       "Regional_Lymph_Nodes_positive                          0.014539   \n",
       "\n",
       "                               Year_of_Last_Contact_or_Death__F  \\\n",
       "Year_of_Diagnosis                                      0.656449   \n",
       "Tumor_Sequence_Number                                  0.127843   \n",
       "Age_At_Diagnosis                                       0.082757   \n",
       "Regional_Lymph_Nodes_examined                          0.105154   \n",
       "Regional_Lymph_Nodes_positive                          0.015377   \n",
       "\n",
       "                               Overall_Survival_1__Days_  \\\n",
       "Year_of_Diagnosis                               0.284000   \n",
       "Tumor_Sequence_Number                           0.044502   \n",
       "Age_At_Diagnosis                                0.204286   \n",
       "Regional_Lymph_Nodes_examined                   0.204488   \n",
       "Regional_Lymph_Nodes_positive                   0.165666   \n",
       "\n",
       "                               Overall_Survival_1__Months_  \\\n",
       "Year_of_Diagnosis                                 0.283572   \n",
       "Tumor_Sequence_Number                             0.044990   \n",
       "Age_At_Diagnosis                                  0.204993   \n",
       "Regional_Lymph_Nodes_examined                     0.203869   \n",
       "Regional_Lymph_Nodes_positive                     0.164628   \n",
       "\n",
       "                               Overall_Survival_2__Days_  ...      8300  \\\n",
       "Year_of_Diagnosis                               0.285061  ...  0.096738   \n",
       "Tumor_Sequence_Number                           0.046955  ...  0.020590   \n",
       "Age_At_Diagnosis                                0.202093  ...  0.105379   \n",
       "Regional_Lymph_Nodes_examined                   0.202699  ...  0.162477   \n",
       "Regional_Lymph_Nodes_positive                   0.164375  ...  0.126528   \n",
       "\n",
       "                                   8301      8304      8305      8307  \\\n",
       "Year_of_Diagnosis              0.024911  0.015518  0.042033  0.051857   \n",
       "Tumor_Sequence_Number          0.039268  0.005099  0.044364  0.073432   \n",
       "Age_At_Diagnosis               0.011552  0.000181  0.017555  0.027586   \n",
       "Regional_Lymph_Nodes_examined  0.144585  0.068971  0.095920  0.075105   \n",
       "Regional_Lymph_Nodes_positive  0.052517  0.043171  0.004640  0.122362   \n",
       "\n",
       "                                   8309      8310      8311      8314  \\\n",
       "Year_of_Diagnosis              0.170086  0.005412  0.049978  0.072603   \n",
       "Tumor_Sequence_Number          0.068132  0.060961  0.075107  0.110043   \n",
       "Age_At_Diagnosis               0.030560  0.007127  0.134809  0.016448   \n",
       "Regional_Lymph_Nodes_examined  0.026212  0.079932  0.013017  0.076088   \n",
       "Regional_Lymph_Nodes_positive  0.027579  0.049116  0.109744  0.073299   \n",
       "\n",
       "                                   8316  \n",
       "Year_of_Diagnosis              0.090380  \n",
       "Tumor_Sequence_Number          0.062217  \n",
       "Age_At_Diagnosis               0.107989  \n",
       "Regional_Lymph_Nodes_examined  0.032443  \n",
       "Regional_Lymph_Nodes_positive  0.080292  \n",
       "\n",
       "[5 rows x 4477 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold for removing correlated variables\n",
    "threshold = 0.75\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = x.corr().abs()\n",
    "print(corr_matrix.shape)\n",
    "corr_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4dad108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4477, 4477)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Diagnosis</th>\n",
       "      <th>Tumor_Sequence_Number</th>\n",
       "      <th>Age_At_Diagnosis</th>\n",
       "      <th>Regional_Lymph_Nodes_examined</th>\n",
       "      <th>Regional_Lymph_Nodes_positive</th>\n",
       "      <th>Year_of_Last_Contact_or_Death__S</th>\n",
       "      <th>Year_of_Last_Contact_or_Death__F</th>\n",
       "      <th>Overall_Survival_1__Days_</th>\n",
       "      <th>Overall_Survival_1__Months_</th>\n",
       "      <th>Overall_Survival_2__Days_</th>\n",
       "      <th>...</th>\n",
       "      <th>8300</th>\n",
       "      <th>8301</th>\n",
       "      <th>8304</th>\n",
       "      <th>8305</th>\n",
       "      <th>8307</th>\n",
       "      <th>8309</th>\n",
       "      <th>8310</th>\n",
       "      <th>8311</th>\n",
       "      <th>8314</th>\n",
       "      <th>8316</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year_of_Diagnosis</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100609</td>\n",
       "      <td>0.074038</td>\n",
       "      <td>0.052394</td>\n",
       "      <td>0.116608</td>\n",
       "      <td>0.662213</td>\n",
       "      <td>0.656449</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.283572</td>\n",
       "      <td>0.285061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096738</td>\n",
       "      <td>0.024911</td>\n",
       "      <td>0.015518</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>0.051857</td>\n",
       "      <td>0.170086</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.049978</td>\n",
       "      <td>0.072603</td>\n",
       "      <td>0.090380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tumor_Sequence_Number</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.265371</td>\n",
       "      <td>0.197846</td>\n",
       "      <td>0.096182</td>\n",
       "      <td>0.114551</td>\n",
       "      <td>0.127843</td>\n",
       "      <td>0.044502</td>\n",
       "      <td>0.044990</td>\n",
       "      <td>0.046955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020590</td>\n",
       "      <td>0.039268</td>\n",
       "      <td>0.005099</td>\n",
       "      <td>0.044364</td>\n",
       "      <td>0.073432</td>\n",
       "      <td>0.068132</td>\n",
       "      <td>0.060961</td>\n",
       "      <td>0.075107</td>\n",
       "      <td>0.110043</td>\n",
       "      <td>0.062217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age_At_Diagnosis</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024481</td>\n",
       "      <td>0.083128</td>\n",
       "      <td>0.089446</td>\n",
       "      <td>0.082757</td>\n",
       "      <td>0.204286</td>\n",
       "      <td>0.204993</td>\n",
       "      <td>0.202093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105379</td>\n",
       "      <td>0.011552</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.017555</td>\n",
       "      <td>0.027586</td>\n",
       "      <td>0.030560</td>\n",
       "      <td>0.007127</td>\n",
       "      <td>0.134809</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.107989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regional_Lymph_Nodes_examined</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214147</td>\n",
       "      <td>0.106061</td>\n",
       "      <td>0.105154</td>\n",
       "      <td>0.204488</td>\n",
       "      <td>0.203869</td>\n",
       "      <td>0.202699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162477</td>\n",
       "      <td>0.144585</td>\n",
       "      <td>0.068971</td>\n",
       "      <td>0.095920</td>\n",
       "      <td>0.075105</td>\n",
       "      <td>0.026212</td>\n",
       "      <td>0.079932</td>\n",
       "      <td>0.013017</td>\n",
       "      <td>0.076088</td>\n",
       "      <td>0.032443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regional_Lymph_Nodes_positive</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014539</td>\n",
       "      <td>0.015377</td>\n",
       "      <td>0.165666</td>\n",
       "      <td>0.164628</td>\n",
       "      <td>0.164375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126528</td>\n",
       "      <td>0.052517</td>\n",
       "      <td>0.043171</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.122362</td>\n",
       "      <td>0.027579</td>\n",
       "      <td>0.049116</td>\n",
       "      <td>0.109744</td>\n",
       "      <td>0.073299</td>\n",
       "      <td>0.080292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4477 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Year_of_Diagnosis  Tumor_Sequence_Number  \\\n",
       "Year_of_Diagnosis                            NaN               0.100609   \n",
       "Tumor_Sequence_Number                        NaN                    NaN   \n",
       "Age_At_Diagnosis                             NaN                    NaN   \n",
       "Regional_Lymph_Nodes_examined                NaN                    NaN   \n",
       "Regional_Lymph_Nodes_positive                NaN                    NaN   \n",
       "\n",
       "                               Age_At_Diagnosis  \\\n",
       "Year_of_Diagnosis                      0.074038   \n",
       "Tumor_Sequence_Number                  0.265371   \n",
       "Age_At_Diagnosis                            NaN   \n",
       "Regional_Lymph_Nodes_examined               NaN   \n",
       "Regional_Lymph_Nodes_positive               NaN   \n",
       "\n",
       "                               Regional_Lymph_Nodes_examined  \\\n",
       "Year_of_Diagnosis                                   0.052394   \n",
       "Tumor_Sequence_Number                               0.197846   \n",
       "Age_At_Diagnosis                                    0.024481   \n",
       "Regional_Lymph_Nodes_examined                            NaN   \n",
       "Regional_Lymph_Nodes_positive                            NaN   \n",
       "\n",
       "                               Regional_Lymph_Nodes_positive  \\\n",
       "Year_of_Diagnosis                                   0.116608   \n",
       "Tumor_Sequence_Number                               0.096182   \n",
       "Age_At_Diagnosis                                    0.083128   \n",
       "Regional_Lymph_Nodes_examined                       0.214147   \n",
       "Regional_Lymph_Nodes_positive                            NaN   \n",
       "\n",
       "                               Year_of_Last_Contact_or_Death__S  \\\n",
       "Year_of_Diagnosis                                      0.662213   \n",
       "Tumor_Sequence_Number                                  0.114551   \n",
       "Age_At_Diagnosis                                       0.089446   \n",
       "Regional_Lymph_Nodes_examined                          0.106061   \n",
       "Regional_Lymph_Nodes_positive                          0.014539   \n",
       "\n",
       "                               Year_of_Last_Contact_or_Death__F  \\\n",
       "Year_of_Diagnosis                                      0.656449   \n",
       "Tumor_Sequence_Number                                  0.127843   \n",
       "Age_At_Diagnosis                                       0.082757   \n",
       "Regional_Lymph_Nodes_examined                          0.105154   \n",
       "Regional_Lymph_Nodes_positive                          0.015377   \n",
       "\n",
       "                               Overall_Survival_1__Days_  \\\n",
       "Year_of_Diagnosis                               0.284000   \n",
       "Tumor_Sequence_Number                           0.044502   \n",
       "Age_At_Diagnosis                                0.204286   \n",
       "Regional_Lymph_Nodes_examined                   0.204488   \n",
       "Regional_Lymph_Nodes_positive                   0.165666   \n",
       "\n",
       "                               Overall_Survival_1__Months_  \\\n",
       "Year_of_Diagnosis                                 0.283572   \n",
       "Tumor_Sequence_Number                             0.044990   \n",
       "Age_At_Diagnosis                                  0.204993   \n",
       "Regional_Lymph_Nodes_examined                     0.203869   \n",
       "Regional_Lymph_Nodes_positive                     0.164628   \n",
       "\n",
       "                               Overall_Survival_2__Days_  ...      8300  \\\n",
       "Year_of_Diagnosis                               0.285061  ...  0.096738   \n",
       "Tumor_Sequence_Number                           0.046955  ...  0.020590   \n",
       "Age_At_Diagnosis                                0.202093  ...  0.105379   \n",
       "Regional_Lymph_Nodes_examined                   0.202699  ...  0.162477   \n",
       "Regional_Lymph_Nodes_positive                   0.164375  ...  0.126528   \n",
       "\n",
       "                                   8301      8304      8305      8307  \\\n",
       "Year_of_Diagnosis              0.024911  0.015518  0.042033  0.051857   \n",
       "Tumor_Sequence_Number          0.039268  0.005099  0.044364  0.073432   \n",
       "Age_At_Diagnosis               0.011552  0.000181  0.017555  0.027586   \n",
       "Regional_Lymph_Nodes_examined  0.144585  0.068971  0.095920  0.075105   \n",
       "Regional_Lymph_Nodes_positive  0.052517  0.043171  0.004640  0.122362   \n",
       "\n",
       "                                   8309      8310      8311      8314  \\\n",
       "Year_of_Diagnosis              0.170086  0.005412  0.049978  0.072603   \n",
       "Tumor_Sequence_Number          0.068132  0.060961  0.075107  0.110043   \n",
       "Age_At_Diagnosis               0.030560  0.007127  0.134809  0.016448   \n",
       "Regional_Lymph_Nodes_examined  0.026212  0.079932  0.013017  0.076088   \n",
       "Regional_Lymph_Nodes_positive  0.027579  0.049116  0.109744  0.073299   \n",
       "\n",
       "                                   8316  \n",
       "Year_of_Diagnosis              0.090380  \n",
       "Tumor_Sequence_Number          0.062217  \n",
       "Age_At_Diagnosis               0.107989  \n",
       "Regional_Lymph_Nodes_examined  0.032443  \n",
       "Regional_Lymph_Nodes_positive  0.080292  \n",
       "\n",
       "[5 rows x 4477 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upper triangle of correlations\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "print(upper.shape)\n",
    "upper.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44a6b619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2283 columns to remove.\n"
     ]
    }
   ],
   "source": [
    "# Select columns with correlations above threshold\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "print('There are %d columns to remove.' % (len(to_drop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03acd79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (103, 2194)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Diagnosis</th>\n",
       "      <th>Tumor_Sequence_Number</th>\n",
       "      <th>Age_At_Diagnosis</th>\n",
       "      <th>Regional_Lymph_Nodes_examined</th>\n",
       "      <th>Regional_Lymph_Nodes_positive</th>\n",
       "      <th>Year_of_Last_Contact_or_Death__S</th>\n",
       "      <th>Overall_Survival_1__Days_</th>\n",
       "      <th>Days_diff_b_w_Diagnosis_and_Spec</th>\n",
       "      <th>Days_diff_b_w_date_of_last_conta</th>\n",
       "      <th>Recurrence__Final_</th>\n",
       "      <th>...</th>\n",
       "      <th>8205</th>\n",
       "      <th>8216</th>\n",
       "      <th>8218</th>\n",
       "      <th>8223</th>\n",
       "      <th>8228</th>\n",
       "      <th>8251</th>\n",
       "      <th>8262</th>\n",
       "      <th>8279</th>\n",
       "      <th>8294</th>\n",
       "      <th>8295</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2740</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.241668</td>\n",
       "      <td>14.947996</td>\n",
       "      <td>15.521010</td>\n",
       "      <td>17.433051</td>\n",
       "      <td>17.812551</td>\n",
       "      <td>17.708263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "      <td>459</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.295241</td>\n",
       "      <td>15.556385</td>\n",
       "      <td>17.563705</td>\n",
       "      <td>18.780560</td>\n",
       "      <td>18.284464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.571433</td>\n",
       "      <td>15.924591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6230</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.159331</td>\n",
       "      <td>15.708085</td>\n",
       "      <td>17.239521</td>\n",
       "      <td>19.302844</td>\n",
       "      <td>17.885742</td>\n",
       "      <td>13.515277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>2825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.249026</td>\n",
       "      <td>16.393885</td>\n",
       "      <td>16.387141</td>\n",
       "      <td>19.165422</td>\n",
       "      <td>18.282855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.260503</td>\n",
       "      <td>16.554338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2537</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.944052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.924618</td>\n",
       "      <td>18.138895</td>\n",
       "      <td>18.298642</td>\n",
       "      <td>13.787291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.521409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Diagnosis  Tumor_Sequence_Number  Age_At_Diagnosis  \\\n",
       "0               2008                      0                64   \n",
       "1               1998                      0                69   \n",
       "2               1998                      0                66   \n",
       "3               2004                      0                72   \n",
       "4               2009                      0                52   \n",
       "\n",
       "   Regional_Lymph_Nodes_examined  Regional_Lymph_Nodes_positive  \\\n",
       "0                             11                              0   \n",
       "1                             12                              0   \n",
       "2                             10                              0   \n",
       "3                             25                              0   \n",
       "4                             18                              0   \n",
       "\n",
       "   Year_of_Last_Contact_or_Death__S  Overall_Survival_1__Days_  \\\n",
       "0                              2015                       2740   \n",
       "1                              1999                        459   \n",
       "2                              2015                       6230   \n",
       "3                              2012                       2825   \n",
       "4                              2015                       2537   \n",
       "\n",
       "   Days_diff_b_w_Diagnosis_and_Spec  Days_diff_b_w_date_of_last_conta  \\\n",
       "0                               141                                 0   \n",
       "1                                31                                 0   \n",
       "2                                60                                 0   \n",
       "3                                 0                                 0   \n",
       "4                                21                                 0   \n",
       "\n",
       "   Recurrence__Final_  ...  8205       8216       8218       8223       8228  \\\n",
       "0                   0  ...   0.0  16.241668  14.947996  15.521010  17.433051   \n",
       "1                   1  ...   0.0   0.000000  14.295241  15.556385  17.563705   \n",
       "2                   0  ...   0.0   0.000000  15.159331  15.708085  17.239521   \n",
       "3                   0  ...   0.0   0.000000  14.249026  16.393885  16.387141   \n",
       "4                   0  ...   0.0   0.000000  14.944052   0.000000  16.924618   \n",
       "\n",
       "        8251       8262       8279       8294       8295  \n",
       "0  17.812551  17.708263   0.000000   0.000000   0.000000  \n",
       "1  18.780560  18.284464   0.000000  16.571433  15.924591  \n",
       "2  19.302844  17.885742  13.515277   0.000000   0.000000  \n",
       "3  19.165422  18.282855   0.000000  17.260503  16.554338  \n",
       "4  18.138895  18.298642  13.787291   0.000000  16.521409  \n",
       "\n",
       "[5 rows x 2194 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_uncorr = x.drop(columns = to_drop)\n",
    "print('Training shape: ', df_uncorr.shape)\n",
    "print(type(df_uncorr))\n",
    "# print the head of the new dataframe\n",
    "df_uncorr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbcca551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features:  103\n",
      "Numerical features:  2194\n"
     ]
    }
   ],
   "source": [
    "# print categorical features\n",
    "print('Categorical features: ', len(df_categorical_features))\n",
    "# print numerical features\n",
    "print('Numerical features: ', len(df_uncorr.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da92664c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (103, 2224)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Diagnosis</th>\n",
       "      <th>Tumor_Sequence_Number</th>\n",
       "      <th>Age_At_Diagnosis</th>\n",
       "      <th>Regional_Lymph_Nodes_examined</th>\n",
       "      <th>Regional_Lymph_Nodes_positive</th>\n",
       "      <th>Year_of_Last_Contact_or_Death__S</th>\n",
       "      <th>Overall_Survival_1__Days_</th>\n",
       "      <th>Days_diff_b_w_Diagnosis_and_Spec</th>\n",
       "      <th>Days_diff_b_w_date_of_last_conta</th>\n",
       "      <th>Recurrence__Final_</th>\n",
       "      <th>...</th>\n",
       "      <th>subtype.1</th>\n",
       "      <th>Tobacco use (FCDS) [Data element retired in 2011]</th>\n",
       "      <th>Recently Reported Cigarette Smoking Status</th>\n",
       "      <th>Recently Reported Tobacco Use</th>\n",
       "      <th>Trypsin.lot.number</th>\n",
       "      <th>Digestion.Start.Time</th>\n",
       "      <th>Digestion.End.Time</th>\n",
       "      <th>TMT.Sample.Name</th>\n",
       "      <th>Proteomic Subtype</th>\n",
       "      <th>Wilkerson Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2740</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Inflamed</td>\n",
       "      <td>MODERATE (1-2 PPD)</td>\n",
       "      <td>EVER</td>\n",
       "      <td>EVER</td>\n",
       "      <td>R5E15825</td>\n",
       "      <td>2:34 PM</td>\n",
       "      <td>11:35 AM</td>\n",
       "      <td>TMT26_TMT-130</td>\n",
       "      <td>Inflamed A</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "      <td>459</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Inflamed</td>\n",
       "      <td>HIST</td>\n",
       "      <td>EVER</td>\n",
       "      <td>EVER</td>\n",
       "      <td>R5E15825</td>\n",
       "      <td>1:00 PM</td>\n",
       "      <td>11:25 AM</td>\n",
       "      <td>TMT23_TMT-131</td>\n",
       "      <td>Inflamed A</td>\n",
       "      <td>secretory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6230</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Inflamed</td>\n",
       "      <td>HIST</td>\n",
       "      <td>EVER</td>\n",
       "      <td>EVER</td>\n",
       "      <td>R5E15825</td>\n",
       "      <td>1:00 PM</td>\n",
       "      <td>11:25 AM</td>\n",
       "      <td>TMT24_TMT-128</td>\n",
       "      <td>Inflamed A</td>\n",
       "      <td>secretory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>2825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Inflamed</td>\n",
       "      <td>NONE</td>\n",
       "      <td>EVER</td>\n",
       "      <td>EVER</td>\n",
       "      <td>R5E15825</td>\n",
       "      <td>1:00 PM</td>\n",
       "      <td>11:25 AM</td>\n",
       "      <td>TMT23_TMT-127</td>\n",
       "      <td>Inflamed A</td>\n",
       "      <td>primitive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2537</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Inflamed</td>\n",
       "      <td>HIST</td>\n",
       "      <td>EVER</td>\n",
       "      <td>EVER</td>\n",
       "      <td>R5E15825</td>\n",
       "      <td>1:54 PM</td>\n",
       "      <td>11:12 AM</td>\n",
       "      <td>TMT10_TMT-127</td>\n",
       "      <td>Inflamed A</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Diagnosis  Tumor_Sequence_Number  Age_At_Diagnosis  \\\n",
       "0               2008                      0                64   \n",
       "1               1998                      0                69   \n",
       "2               1998                      0                66   \n",
       "3               2004                      0                72   \n",
       "4               2009                      0                52   \n",
       "\n",
       "   Regional_Lymph_Nodes_examined  Regional_Lymph_Nodes_positive  \\\n",
       "0                             11                              0   \n",
       "1                             12                              0   \n",
       "2                             10                              0   \n",
       "3                             25                              0   \n",
       "4                             18                              0   \n",
       "\n",
       "   Year_of_Last_Contact_or_Death__S  Overall_Survival_1__Days_  \\\n",
       "0                              2015                       2740   \n",
       "1                              1999                        459   \n",
       "2                              2015                       6230   \n",
       "3                              2012                       2825   \n",
       "4                              2015                       2537   \n",
       "\n",
       "   Days_diff_b_w_Diagnosis_and_Spec  Days_diff_b_w_date_of_last_conta  \\\n",
       "0                               141                                 0   \n",
       "1                                31                                 0   \n",
       "2                                60                                 0   \n",
       "3                                 0                                 0   \n",
       "4                                21                                 0   \n",
       "\n",
       "   Recurrence__Final_  ...  subtype.1  \\\n",
       "0                   0  ...   Inflamed   \n",
       "1                   1  ...   Inflamed   \n",
       "2                   0  ...   Inflamed   \n",
       "3                   0  ...   Inflamed   \n",
       "4                   0  ...   Inflamed   \n",
       "\n",
       "   Tobacco use (FCDS) [Data element retired in 2011]  \\\n",
       "0                                 MODERATE (1-2 PPD)   \n",
       "1                                               HIST   \n",
       "2                                               HIST   \n",
       "3                                               NONE   \n",
       "4                                               HIST   \n",
       "\n",
       "   Recently Reported Cigarette Smoking Status  Recently Reported Tobacco Use  \\\n",
       "0                                        EVER                           EVER   \n",
       "1                                        EVER                           EVER   \n",
       "2                                        EVER                           EVER   \n",
       "3                                        EVER                           EVER   \n",
       "4                                        EVER                           EVER   \n",
       "\n",
       "   Trypsin.lot.number  Digestion.Start.Time  Digestion.End.Time  \\\n",
       "0            R5E15825               2:34 PM            11:35 AM   \n",
       "1            R5E15825               1:00 PM            11:25 AM   \n",
       "2            R5E15825               1:00 PM            11:25 AM   \n",
       "3            R5E15825               1:00 PM            11:25 AM   \n",
       "4            R5E15825               1:54 PM            11:12 AM   \n",
       "\n",
       "   TMT.Sample.Name  Proteomic Subtype  Wilkerson Classification  \n",
       "0    TMT26_TMT-130         Inflamed A                 classical  \n",
       "1    TMT23_TMT-131         Inflamed A                 secretory  \n",
       "2    TMT24_TMT-128         Inflamed A                 secretory  \n",
       "3    TMT23_TMT-127         Inflamed A                 primitive  \n",
       "4    TMT10_TMT-127         Inflamed A                 classical  \n",
       "\n",
       "[5 rows x 2224 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the numerical features and categorical features\n",
    "df_uncorr = pd.concat([df_uncorr, df_categorical_features], axis=1)\n",
    "print('Training shape: ', df_uncorr.shape)\n",
    "print(type(df_uncorr))\n",
    "# print the head of the new dataframe\n",
    "df_uncorr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d46856a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (103, 2516)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Diagnosis</th>\n",
       "      <th>Tumor_Sequence_Number</th>\n",
       "      <th>Age_At_Diagnosis</th>\n",
       "      <th>Regional_Lymph_Nodes_examined</th>\n",
       "      <th>Regional_Lymph_Nodes_positive</th>\n",
       "      <th>Year_of_Last_Contact_or_Death__S</th>\n",
       "      <th>Overall_Survival_1__Days_</th>\n",
       "      <th>Days_diff_b_w_Diagnosis_and_Spec</th>\n",
       "      <th>Days_diff_b_w_date_of_last_conta</th>\n",
       "      <th>Recurrence__Final_</th>\n",
       "      <th>...</th>\n",
       "      <th>TMT.Sample.Name_TMT29_TMT-131</th>\n",
       "      <th>Proteomic Subtype_Inflamed A</th>\n",
       "      <th>Proteomic Subtype_Inflamed B</th>\n",
       "      <th>Proteomic Subtype_Mixed</th>\n",
       "      <th>Proteomic Subtype_Redox A</th>\n",
       "      <th>Proteomic Subtype_Redox B</th>\n",
       "      <th>Wilkerson Classification_basal</th>\n",
       "      <th>Wilkerson Classification_classical</th>\n",
       "      <th>Wilkerson Classification_primitive</th>\n",
       "      <th>Wilkerson Classification_secretory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2740</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "      <td>459</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>6230</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>2825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2537</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2516 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Diagnosis  Tumor_Sequence_Number  Age_At_Diagnosis  \\\n",
       "0               2008                      0                64   \n",
       "1               1998                      0                69   \n",
       "2               1998                      0                66   \n",
       "3               2004                      0                72   \n",
       "4               2009                      0                52   \n",
       "\n",
       "   Regional_Lymph_Nodes_examined  Regional_Lymph_Nodes_positive  \\\n",
       "0                             11                              0   \n",
       "1                             12                              0   \n",
       "2                             10                              0   \n",
       "3                             25                              0   \n",
       "4                             18                              0   \n",
       "\n",
       "   Year_of_Last_Contact_or_Death__S  Overall_Survival_1__Days_  \\\n",
       "0                              2015                       2740   \n",
       "1                              1999                        459   \n",
       "2                              2015                       6230   \n",
       "3                              2012                       2825   \n",
       "4                              2015                       2537   \n",
       "\n",
       "   Days_diff_b_w_Diagnosis_and_Spec  Days_diff_b_w_date_of_last_conta  \\\n",
       "0                               141                                 0   \n",
       "1                                31                                 0   \n",
       "2                                60                                 0   \n",
       "3                                 0                                 0   \n",
       "4                                21                                 0   \n",
       "\n",
       "   Recurrence__Final_  ...  TMT.Sample.Name_TMT29_TMT-131  \\\n",
       "0                   0  ...                              0   \n",
       "1                   1  ...                              0   \n",
       "2                   0  ...                              0   \n",
       "3                   0  ...                              0   \n",
       "4                   0  ...                              0   \n",
       "\n",
       "   Proteomic Subtype_Inflamed A  Proteomic Subtype_Inflamed B  \\\n",
       "0                             1                             0   \n",
       "1                             1                             0   \n",
       "2                             1                             0   \n",
       "3                             1                             0   \n",
       "4                             1                             0   \n",
       "\n",
       "   Proteomic Subtype_Mixed  Proteomic Subtype_Redox A  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   Proteomic Subtype_Redox B  Wilkerson Classification_basal  \\\n",
       "0                          0                               0   \n",
       "1                          0                               0   \n",
       "2                          0                               0   \n",
       "3                          0                               0   \n",
       "4                          0                               0   \n",
       "\n",
       "   Wilkerson Classification_classical  Wilkerson Classification_primitive  \\\n",
       "0                                   1                                   0   \n",
       "1                                   0                                   0   \n",
       "2                                   0                                   0   \n",
       "3                                   0                                   1   \n",
       "4                                   1                                   0   \n",
       "\n",
       "   Wilkerson Classification_secretory  \n",
       "0                                   0  \n",
       "1                                   1  \n",
       "2                                   1  \n",
       "3                                   0  \n",
       "4                                   0  \n",
       "\n",
       "[5 rows x 2516 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot encoding\n",
    "df_uncorr = pd.get_dummies(df_uncorr)\n",
    "print('Training shape: ', df_uncorr.shape)\n",
    "print(type(df_uncorr))\n",
    "# print the head of the new dataframe\n",
    "df_uncorr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7d2276d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Overall_Survival_1__Days_'], dtype='object')\n",
      "Index(['sample_name_SCC001', 'sample_name_SCC002', 'sample_name_SCC003',\n",
      "       'sample_name_SCC004', 'sample_name_SCC005', 'sample_name_SCC006',\n",
      "       'sample_name_SCC007', 'sample_name_SCC008', 'sample_name_SCC009',\n",
      "       'sample_name_SCC010',\n",
      "       ...\n",
      "       'sample_name_SCC098', 'sample_name_SCC099', 'sample_name_SCC100',\n",
      "       'sample_name_SCC101', 'sample_name_SCC103', 'sample_name_SCC104',\n",
      "       'sample_name_SCC105', 'sample_name_SCC106', 'sample_name_SCC107',\n",
      "       'sample_name_SCC108'],\n",
      "      dtype='object', length=103)\n"
     ]
    }
   ],
   "source": [
    "# Print columns having names with 'Overall_Survival'\n",
    "print(df_uncorr.columns[df_uncorr.columns.str.contains('Survival')])\n",
    "print(df_uncorr.columns[df_uncorr.columns.str.contains('sample_name')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d524b4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 103 columns that contain sample_name\n"
     ]
    }
   ],
   "source": [
    "# Remove the one-hot columns having sample names\n",
    "cols_with_id = [x for x in df_uncorr.columns if 'sample_name' in x]\n",
    "print('There are %d columns that contain sample_name' % len(cols_with_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93a49fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:  (103, 2413)\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Drop the columns with sample_name\n",
    "df_data = df_uncorr.drop(columns = cols_with_id)\n",
    "print('Training shape: ', df_data.shape)\n",
    "print(type(df_data))\n",
    "# print the head of the new dataframe\n",
    "df_data.head()\n",
    "# save the dataframe to a .xlxs file\n",
    "df_data.to_excel('data/Data-Processed_uncorr.xlsx', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44b72f03",
   "metadata": {},
   "source": [
    "## VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d35bb011",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    44\n",
      "0    31\n",
      "1    28\n",
      "Name: Overall_Survival_1__Days_, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Diagnosis</th>\n",
       "      <th>Tumor_Sequence_Number</th>\n",
       "      <th>Age_At_Diagnosis</th>\n",
       "      <th>Regional_Lymph_Nodes_examined</th>\n",
       "      <th>Regional_Lymph_Nodes_positive</th>\n",
       "      <th>Year_of_Last_Contact_or_Death__S</th>\n",
       "      <th>Overall_Survival_1__Days_</th>\n",
       "      <th>Days_diff_b_w_Diagnosis_and_Spec</th>\n",
       "      <th>Days_diff_b_w_date_of_last_conta</th>\n",
       "      <th>Recurrence__Final_</th>\n",
       "      <th>...</th>\n",
       "      <th>TMT.Sample.Name_TMT29_TMT-131</th>\n",
       "      <th>Proteomic Subtype_Inflamed A</th>\n",
       "      <th>Proteomic Subtype_Inflamed B</th>\n",
       "      <th>Proteomic Subtype_Mixed</th>\n",
       "      <th>Proteomic Subtype_Redox A</th>\n",
       "      <th>Proteomic Subtype_Redox B</th>\n",
       "      <th>Wilkerson Classification_basal</th>\n",
       "      <th>Wilkerson Classification_classical</th>\n",
       "      <th>Wilkerson Classification_primitive</th>\n",
       "      <th>Wilkerson Classification_secretory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2413 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Diagnosis  Tumor_Sequence_Number  Age_At_Diagnosis  \\\n",
       "0               2008                      0                64   \n",
       "1               1998                      0                69   \n",
       "2               1998                      0                66   \n",
       "3               2004                      0                72   \n",
       "4               2009                      0                52   \n",
       "\n",
       "   Regional_Lymph_Nodes_examined  Regional_Lymph_Nodes_positive  \\\n",
       "0                             11                              0   \n",
       "1                             12                              0   \n",
       "2                             10                              0   \n",
       "3                             25                              0   \n",
       "4                             18                              0   \n",
       "\n",
       "   Year_of_Last_Contact_or_Death__S  Overall_Survival_1__Days_  \\\n",
       "0                              2015                          2   \n",
       "1                              1999                          0   \n",
       "2                              2015                          2   \n",
       "3                              2012                          2   \n",
       "4                              2015                          2   \n",
       "\n",
       "   Days_diff_b_w_Diagnosis_and_Spec  Days_diff_b_w_date_of_last_conta  \\\n",
       "0                               141                                 0   \n",
       "1                                31                                 0   \n",
       "2                                60                                 0   \n",
       "3                                 0                                 0   \n",
       "4                                21                                 0   \n",
       "\n",
       "   Recurrence__Final_  ...  TMT.Sample.Name_TMT29_TMT-131  \\\n",
       "0                   0  ...                              0   \n",
       "1                   1  ...                              0   \n",
       "2                   0  ...                              0   \n",
       "3                   0  ...                              0   \n",
       "4                   0  ...                              0   \n",
       "\n",
       "   Proteomic Subtype_Inflamed A  Proteomic Subtype_Inflamed B  \\\n",
       "0                             1                             0   \n",
       "1                             1                             0   \n",
       "2                             1                             0   \n",
       "3                             1                             0   \n",
       "4                             1                             0   \n",
       "\n",
       "   Proteomic Subtype_Mixed  Proteomic Subtype_Redox A  \\\n",
       "0                        0                          0   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "\n",
       "   Proteomic Subtype_Redox B  Wilkerson Classification_basal  \\\n",
       "0                          0                               0   \n",
       "1                          0                               0   \n",
       "2                          0                               0   \n",
       "3                          0                               0   \n",
       "4                          0                               0   \n",
       "\n",
       "   Wilkerson Classification_classical  Wilkerson Classification_primitive  \\\n",
       "0                                   1                                   0   \n",
       "1                                   0                                   0   \n",
       "2                                   0                                   0   \n",
       "3                                   0                                   1   \n",
       "4                                   1                                   0   \n",
       "\n",
       "   Wilkerson Classification_secretory  \n",
       "0                                   0  \n",
       "1                                   1  \n",
       "2                                   1  \n",
       "3                                   0  \n",
       "4                                   0  \n",
       "\n",
       "[5 rows x 2413 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Class labels for training\n",
    "# convert the df_data['Overall_Survival_1__Days_'] column values to three classes based on thresholds\n",
    "labels = np.array(df_data['Overall_Survival_1__Days_'])\n",
    "labels[labels <= 730] = 0   # 2 years\n",
    "labels[(labels > 730) & (labels <= 2190)] = 1 # between 2 and 6 years\n",
    "labels[labels > 2190] = 2   # greater than 6 years\n",
    "df_data['Overall_Survival_1__Days_'] = labels\n",
    "\n",
    "print(df_data['Overall_Survival_1__Days_'].value_counts())\n",
    "# print(df_data['Overall_Survival_1__Days_'])\n",
    "# save the dataframe to a .xlxs file\n",
    "df_data.to_excel('data/Data-Processed_uncorr_class-labled.xlsx', index=False)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94804171",
   "metadata": {},
   "source": [
    "### Training, Validation Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1040735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is split into 5 stratified training and validation folds with each set saved to new csv files for later use.\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "target = df_data['Overall_Survival_1__Days_']\n",
    "fold_no=1\n",
    "for train_index, test_index in skf.split(df_data, target):\n",
    "    train = df_data.iloc[train_index]\n",
    "    test = df_data.iloc[test_index]\n",
    "    if not os.path.exists('data/folds/training_folds/fold{}'.format(fold_no)):\n",
    "        os.makedirs('data/folds/training_folds/fold{}'.format(fold_no))\n",
    "    train.to_csv('data/folds/training_folds/fold{}/train_fold_{}.csv'.format(fold_no, fold_no), index=False)\n",
    "    if not os.path.exists('data/folds/validation_folds/fold{}'.format(fold_no)):\n",
    "        os.makedirs('data/folds/validation_folds/fold{}'.format(fold_no))\n",
    "    test.to_csv('data/folds/validation_folds/fold{}/test_fold_{}.csv'.format(fold_no, fold_no), index=False)\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36361b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:  1\n",
      "Fold # 1 features and lables saved to csv files in folder: data/fold1\n",
      "Fold:  2\n",
      "Fold # 2 features and lables saved to csv files in folder: data/fold2\n",
      "Fold:  3\n",
      "Fold # 3 features and lables saved to csv files in folder: data/fold3\n",
      "Fold:  4\n",
      "Fold # 4 features and lables saved to csv files in folder: data/fold4\n",
      "Fold:  5\n",
      "Fold # 5 features and lables saved to csv files in folder: data/fold5\n"
     ]
    }
   ],
   "source": [
    "# load all kfold files and create training and testing labels\n",
    "for i in range(1, 6):\n",
    "    train = pd.read_csv('data/folds/training_folds/fold{}/train_fold_{}.csv'.format(i,i))\n",
    "    test = pd.read_csv('data/folds/validation_folds/fold{}/test_fold_{}.csv'.format(i,i))\n",
    "    train_labels = np.array(train['Overall_Survival_1__Days_'])\n",
    "    test_labels = np.array(test['Overall_Survival_1__Days_'])\n",
    "    print('Fold: ', i)\n",
    "    # Remove the labels from the features\n",
    "    # axis 1 refers to the columns\n",
    "    train = train.drop('Overall_Survival_1__Days_', axis = 1)\n",
    "    test = test.drop('Overall_Survival_1__Days_', axis = 1)\n",
    "    # Saving the features and labels to csv files\n",
    "    train.to_csv('data/folds/training_folds/fold{}/train_fold_{}_features.csv'.format(i,i), index=False)\n",
    "    test.to_csv('data/folds/validation_folds/fold{}/test_fold_{}_features.csv'.format(i,i), index=False)\n",
    "    np.savetxt('data/folds/training_folds/fold{}/train_fold_{}_labels.csv'.format(i,i), train_labels, delimiter=',', fmt='%d')\n",
    "    np.savetxt('data/folds/validation_folds/fold{}/test_fold_{}_labels.csv'.format(i,i), test_labels, delimiter=',', fmt='%d')\n",
    "    print(\"Fold # {} features and lables saved to csv files in folder: data/fold{}\".format(i,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f693cb2",
   "metadata": {},
   "source": [
    "### Prepare data in graphs form for use by GNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2b7c1aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 2412)\n",
      "(82, 82)\n",
      "(82, 82)\n",
      "Fold : 1 done\n",
      "(82, 2412)\n",
      "(82, 82)\n",
      "(82, 82)\n",
      "Fold : 2 done\n",
      "(82, 2412)\n",
      "(82, 82)\n",
      "(82, 82)\n",
      "Fold : 3 done\n",
      "(83, 2412)\n",
      "(83, 83)\n",
      "(83, 83)\n",
      "Fold : 4 done\n",
      "(83, 2412)\n",
      "(83, 83)\n",
      "(83, 83)\n",
      "Fold : 5 done\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix of normalized euclidean distance from df_data for patients\n",
    "# For Train Folds\n",
    "for i in range(1, 6):\n",
    "    train_df_data = pd.read_csv('data/folds/training_folds/fold{}/train_fold_{}_features.csv'.format(i,i))    \n",
    "    train_patient_dist_matrix = np.zeros((train_df_data.shape[0], train_df_data.shape[0]))\n",
    "    print(train_df_data.shape)\n",
    "    for j in range(train_df_data.shape[0]):\n",
    "        for k in range(train_df_data.shape[0]):\n",
    "            train_patient_dist_matrix[j][k] = np.linalg.norm(train_df_data.iloc[j] - train_df_data.iloc[k])\n",
    "    print(train_patient_dist_matrix.shape)\n",
    "    # normalize the matrix to [0, 1]\n",
    "    train_patient_dist_matrix = (train_patient_dist_matrix - train_patient_dist_matrix.min()) / (train_patient_dist_matrix.max() - train_patient_dist_matrix.min())\n",
    "    print(train_patient_dist_matrix.shape)\n",
    "    # print(train_patient_dist_matrix)\n",
    "    np.savetxt('data/folds/training_folds/fold{}/fold_{}_train_patient_dist_matrix.csv'.format(i,i), train_patient_dist_matrix, delimiter=',', fmt='%f')\n",
    "    # print(\"Fold # {} patient distance matrix saved to csv files in folder: data/fold{}\".format(i,i))\n",
    "    print('Fold :', i, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b7ae381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 2412)\n",
      "(21, 21)\n",
      "Fold : 1 done\n",
      "(21, 2412)\n",
      "(21, 21)\n",
      "Fold : 2 done\n",
      "(21, 2412)\n",
      "(21, 21)\n",
      "Fold : 3 done\n",
      "(20, 2412)\n",
      "(20, 20)\n",
      "Fold : 4 done\n",
      "(20, 2412)\n",
      "(20, 20)\n",
      "Fold : 5 done\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix of normalized euclidean distance from df_data for patients\n",
    "# For Test Folds\n",
    "for i in range(1, 6):\n",
    "    test_df_data = pd.read_csv('data/folds/validation_folds/fold{}/test_fold_{}_features.csv'.format(i,i))    \n",
    "    test_patient_dist_matrix = np.zeros((test_df_data.shape[0], test_df_data.shape[0]))\n",
    "    print(test_df_data.shape)\n",
    "    for j in range(test_df_data.shape[0]):\n",
    "        for k in range(test_df_data.shape[0]):\n",
    "            test_patient_dist_matrix[j][k] = np.linalg.norm(test_df_data.iloc[j] - test_df_data.iloc[k])\n",
    "    print(test_patient_dist_matrix.shape)\n",
    "    # normalize the matrix to [0, 1]\n",
    "    test_patient_dist_matrix = (test_patient_dist_matrix - test_patient_dist_matrix.min()) / (test_patient_dist_matrix.max() - test_patient_dist_matrix.min())\n",
    "    # print(test_patient_dist_matrix)\n",
    "    np.savetxt('data/folds/validation_folds/fold{}/fold_{}_test_patient_dist_matrix.csv'.format(i,i), test_patient_dist_matrix, delimiter=',', fmt='%f')\n",
    "    # print(\"Fold # {} patient distance matrix saved to csv files in folder: data/fold{}\".format(i,i))\n",
    "    print('Fold :', i, 'done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d7de580",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** Starting Fold : 1 ********************\n",
      "Loading folder: data/folds/training_folds/fold1\n",
      "Adjacency matrix shape: (82, 82)  Node features shape: (82, 2412)  Labels shape: (82, 1)\n",
      "num_nodes: 82 , num_features: 2412 , num_labels: 82 , num_classes: 3\n",
      "zero_count: 82\n",
      "Edge indices shape: (2, 6642)  Edge attributes shape: (6642,)\n",
      "****************** Starting Fold : 2 ********************\n",
      "Loading folder: data/folds/training_folds/fold2\n",
      "Adjacency matrix shape: (82, 82)  Node features shape: (82, 2412)  Labels shape: (82, 1)\n",
      "num_nodes: 82 , num_features: 2412 , num_labels: 82 , num_classes: 3\n",
      "zero_count: 82\n",
      "Edge indices shape: (2, 6642)  Edge attributes shape: (6642,)\n",
      "****************** Starting Fold : 3 ********************\n",
      "Loading folder: data/folds/training_folds/fold3\n",
      "Adjacency matrix shape: (82, 82)  Node features shape: (82, 2412)  Labels shape: (82, 1)\n",
      "num_nodes: 82 , num_features: 2412 , num_labels: 82 , num_classes: 3\n",
      "zero_count: 82\n",
      "Edge indices shape: (2, 6642)  Edge attributes shape: (6642,)\n",
      "****************** Starting Fold : 4 ********************\n",
      "Loading folder: data/folds/training_folds/fold4\n",
      "Adjacency matrix shape: (83, 83)  Node features shape: (83, 2412)  Labels shape: (83, 1)\n",
      "num_nodes: 83 , num_features: 2412 , num_labels: 83 , num_classes: 3\n",
      "zero_count: 83\n",
      "Edge indices shape: (2, 6806)  Edge attributes shape: (6806,)\n",
      "****************** Starting Fold : 5 ********************\n",
      "Loading folder: data/folds/training_folds/fold5\n",
      "Adjacency matrix shape: (83, 83)  Node features shape: (83, 2412)  Labels shape: (83, 1)\n",
      "num_nodes: 83 , num_features: 2412 , num_labels: 83 , num_classes: 3\n",
      "zero_count: 83\n",
      "Edge indices shape: (2, 6806)  Edge attributes shape: (6806,)\n"
     ]
    }
   ],
   "source": [
    "# generate edge indices and edge attributes for each training fold\n",
    "for k in range(1, 6):\n",
    "    print('****************** Starting Fold :', k, '********************')\n",
    "    print('Loading folder: data/folds/training_folds/fold{}'.format(k)) \n",
    "    labels = pd.read_csv('data/folds/training_folds/fold{}/train_fold_{}_labels.csv'.format(k,k), header=None).values\n",
    "    node_features = pd.read_csv('data/folds/training_folds/fold{}/train_fold_{}_features.csv'.format(k,k), skiprows=1, header=None).values\n",
    "    adj = pd.read_csv('data/folds/training_folds/fold{}/fold_{}_train_patient_dist_matrix.csv'.format(k,k), header=None).values   # Adjacency matrix (num_nodes, num_nodes)\n",
    "    print('Adjacency matrix shape:', adj.shape, ' Node features shape:', node_features.shape, ' Labels shape:', labels.shape)\n",
    "\n",
    "    num_nodes = adj.shape[0]\n",
    "    num_features = node_features.shape[1]\n",
    "    num_labels = labels.shape[0]\n",
    "    num_classes = 3\n",
    "    print('num_nodes:',num_nodes, ', num_features:',num_features, ', num_labels:',num_labels, ', num_classes:',num_classes)\n",
    "    # count the zero elements in the adjacency matrix\n",
    "    zero_count = 0\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if adj[i][j] == 0:\n",
    "                zero_count += 1\n",
    "    print('zero_count:',zero_count)\n",
    "\n",
    "    # Generate edge indices and edge attributes\n",
    "    edge_indices = []\n",
    "    edge_attributes = []\n",
    "    for l in range(num_nodes):\n",
    "        for m in range(num_nodes):\n",
    "            if adj[l][m] > 0:\n",
    "                edge_indices.append([l,m])\n",
    "                edge_attributes.append(adj[l][m])\n",
    "    edge_indices = np.array(edge_indices).T  # (2, num_edges) where num_edges = num_nodes * num_nodes - zero_count\n",
    "    edge_attributes = np.array(edge_attributes)\n",
    "    print('Edge indices shape:', edge_indices.shape, ' Edge attributes shape:', edge_attributes.shape)\n",
    "    # print first 6 instances of edge_index and edge_attr\n",
    "    # print('edge_index:',edge_indices[:,:6])\n",
    "    # print('edge_attr:',edge_attributes[:6])\n",
    "\n",
    "    # check validity of edge_index and edge_attr\n",
    "    for a in range(edge_indices.shape[1]):\n",
    "        if edge_indices[0][a] == edge_indices[1][a]:\n",
    "            print('Self loop found at index:', a)\n",
    "    for b in range(edge_attributes.shape[0]):\n",
    "        if edge_attributes[b] == 0:\n",
    "            print('Zero edge attribute found at index:', b)\n",
    "    # save edge indices and edge attributes to csv files\n",
    "    np.savetxt('data/folds/training_folds/fold{}/fold_{}_train_edge_indices.csv'.format(k,k), edge_indices, delimiter=',', fmt='%d')\n",
    "    np.savetxt('data/folds/training_folds/fold{}/fold_{}_train_edge_attributes.csv'.format(k,k), edge_attributes, delimiter=',', fmt='%f')\n",
    "    \n",
    "# # create node coordinates\n",
    "# node_coordinates = np.zeros((num_nodes, 2))\n",
    "# for i in range(num_nodes):\n",
    "#     node_coordinates[i][0] = i\n",
    "#     node_coordinates[i][1] = i\n",
    "# print('node_coordinates:',node_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62d35c67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************** Starting Fold : 1 ********************\n",
      "Loading folder: data/folds/validation_folds/fold1\n",
      "Adjacency matrix shape: (21, 21)  Node features shape: (21, 2412)  Labels shape: (21, 1)\n",
      "num_nodes: 21 , num_features: 2412 , num_labels: 21 , num_classes: 3\n",
      "zero_count: 21\n",
      "Edge indices shape: (2, 420)  Edge attributes shape: (420,)\n",
      "****************** Starting Fold : 2 ********************\n",
      "Loading folder: data/folds/validation_folds/fold2\n",
      "Adjacency matrix shape: (21, 21)  Node features shape: (21, 2412)  Labels shape: (21, 1)\n",
      "num_nodes: 21 , num_features: 2412 , num_labels: 21 , num_classes: 3\n",
      "zero_count: 21\n",
      "Edge indices shape: (2, 420)  Edge attributes shape: (420,)\n",
      "****************** Starting Fold : 3 ********************\n",
      "Loading folder: data/folds/validation_folds/fold3\n",
      "Adjacency matrix shape: (21, 21)  Node features shape: (21, 2412)  Labels shape: (21, 1)\n",
      "num_nodes: 21 , num_features: 2412 , num_labels: 21 , num_classes: 3\n",
      "zero_count: 21\n",
      "Edge indices shape: (2, 420)  Edge attributes shape: (420,)\n",
      "****************** Starting Fold : 4 ********************\n",
      "Loading folder: data/folds/validation_folds/fold4\n",
      "Adjacency matrix shape: (20, 20)  Node features shape: (20, 2412)  Labels shape: (20, 1)\n",
      "num_nodes: 20 , num_features: 2412 , num_labels: 20 , num_classes: 3\n",
      "zero_count: 20\n",
      "Edge indices shape: (2, 380)  Edge attributes shape: (380,)\n",
      "****************** Starting Fold : 5 ********************\n",
      "Loading folder: data/folds/validation_folds/fold5\n",
      "Adjacency matrix shape: (20, 20)  Node features shape: (20, 2412)  Labels shape: (20, 1)\n",
      "num_nodes: 20 , num_features: 2412 , num_labels: 20 , num_classes: 3\n",
      "zero_count: 20\n",
      "Edge indices shape: (2, 380)  Edge attributes shape: (380,)\n"
     ]
    }
   ],
   "source": [
    "# generate edge indices and edge attributes for each validation fold\n",
    "for k in range(1, 6):\n",
    "    print('****************** Starting Fold :', k, '********************')\n",
    "    print('Loading folder: data/folds/validation_folds/fold{}'.format(k)) \n",
    "    labels = pd.read_csv('data/folds/validation_folds/fold{}/test_fold_{}_labels.csv'.format(k,k), header=None).values\n",
    "    node_features = pd.read_csv('data/folds/validation_folds/fold{}/test_fold_{}_features.csv'.format(k,k), skiprows=1, header=None).values\n",
    "    adj = pd.read_csv('data/folds/validation_folds/fold{}/fold_{}_test_patient_dist_matrix.csv'.format(k,k), header=None).values   # Adjacency matrix (num_nodes, num_nodes)\n",
    "    print('Adjacency matrix shape:', adj.shape, ' Node features shape:', node_features.shape, ' Labels shape:', labels.shape)\n",
    "\n",
    "    num_nodes = adj.shape[0]\n",
    "    num_features = node_features.shape[1]\n",
    "    num_labels = labels.shape[0]\n",
    "    num_classes = 3\n",
    "    print('num_nodes:',num_nodes, ', num_features:',num_features, ', num_labels:',num_labels, ', num_classes:',num_classes)\n",
    "    # count the zero elements in the adjacency matrix\n",
    "    zero_count = 0\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if adj[i][j] == 0:\n",
    "                zero_count += 1\n",
    "    print('zero_count:',zero_count)\n",
    "\n",
    "    # Generate edge indices and edge attributes\n",
    "    edge_indices = []\n",
    "    edge_attributes = []\n",
    "    for l in range(num_nodes):\n",
    "        for m in range(num_nodes):\n",
    "            if adj[l][m] > 0:\n",
    "                edge_indices.append([l,m])\n",
    "                edge_attributes.append(adj[l][m])\n",
    "    edge_indices = np.array(edge_indices).T  # (2, num_edges) where num_edges = num_nodes * num_nodes - zero_count\n",
    "    edge_attributes = np.array(edge_attributes)\n",
    "    print('Edge indices shape:', edge_indices.shape, ' Edge attributes shape:', edge_attributes.shape)\n",
    "    # print first 6 instances of edge_index and edge_attr\n",
    "    # print('edge_index:',edge_indices[:,:6])\n",
    "    # print('edge_attr:',edge_attributes[:6])\n",
    "\n",
    "    # check validity of edge_index and edge_attr\n",
    "    for a in range(edge_indices.shape[1]):\n",
    "        if edge_indices[0][a] == edge_indices[1][a]:\n",
    "            print('Self loop found at index:', a)\n",
    "    for b in range(edge_attributes.shape[0]):\n",
    "        if edge_attributes[b] == 0:\n",
    "            print('Zero edge attribute found at index:', b)\n",
    "    # save edge indices and edge attributes to csv files\n",
    "    np.savetxt('data/folds/validation_folds/fold{}/fold_{}_test_edge_indices.csv'.format(k,k), edge_indices, delimiter=',', fmt='%d')\n",
    "    np.savetxt('data/folds/validation_folds/fold{}/fold_{}_test_edge_attributes.csv'.format(k,k), edge_attributes, delimiter=',', fmt='%f')\n",
    "    \n",
    "# # create node coordinates\n",
    "# node_coordinates = np.zeros((num_nodes, 2))\n",
    "# for i in range(num_nodes):\n",
    "#     node_coordinates[i][0] = i\n",
    "#     node_coordinates[i][1] = i\n",
    "# print('node_coordinates:',node_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b65d01",
   "metadata": {},
   "source": [
    "# Pytorch Geomteric & GNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f450d9",
   "metadata": {},
   "source": [
    "### Create custom data loader for torch.geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8eeaaae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages from torch_geometric\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU\n",
    "\n",
    "from torch_geometric.nn import GraphConv, GINConv, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.data import DataListLoader\n",
    "from torch_geometric.data import Batch\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch_geometric.data import ClusterData\n",
    "from torch_geometric.data import ClusterLoader\n",
    "from torch_geometric.data import ClusterLoader\n",
    "from torch_geometric.data import ClusterData\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.loader import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe202e3",
   "metadata": {},
   "source": [
    "### GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74cafedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GNN model, GINTopK\n",
    "class GINTopK(torch.nn.Module):\n",
    "    def __init__(self, num_feature, num_class, nhid):\n",
    "        super(GINTopK, self).__init__()\n",
    "        self.conv1 = GINConv(Seq(Lin(num_feature, nhid), ReLU(), Lin(nhid, nhid)))\n",
    "        self.pool1 = TopKPooling(nhid, ratio=0.8)\n",
    "        self.conv2 = GINConv(Seq(Lin(nhid, nhid), ReLU(), Lin(nhid, nhid)))\n",
    "        self.pool2 = TopKPooling(nhid, ratio=0.8)\n",
    "        self.conv3 = GINConv(Seq(Lin(nhid, nhid), ReLU(), Lin(nhid, nhid)))\n",
    "        self.pool3 = TopKPooling(nhid, ratio=0.8)\n",
    "        self.conv4 = GINConv(Seq(Lin(nhid, nhid), ReLU(), Lin(nhid, nhid)))\n",
    "        self.pool4 = TopKPooling(nhid, ratio=0.8)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(2*nhid, nhid)\n",
    "        self.lin2 = torch.nn.Linear(nhid, nhid//2)\n",
    "        self.lin3 = torch.nn.Linear(nhid//2, num_class)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        print(f\"==============> x : {x.shape}, edge_index : {edge_index.shape} <===============\")\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool1(x, edge_index, None, batch)\n",
    "        x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "        print(f\"==============> x_post_conv1 : {x.shape} <===============\")\n",
    "        print(f\"==============> x1 : {x1.shape} <===============\")\n",
    "\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool2(x, edge_index, None, batch)\n",
    "        x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "        print(f\"==============> x_post_conv2 : {x.shape} <===============\")\n",
    "        print(f\"==============> x2 : {x2.shape} <===============\")\n",
    "\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool3(x, edge_index, None, batch)\n",
    "        x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "        print(f\"==============> x_post_conv3 : {x.shape} <===============\")\n",
    "        print(f\"==============> x3 : {x3.shape} <===============\")\n",
    "        \n",
    "        x = F.relu(self.conv4(x, edge_index))\n",
    "        x, edge_index, _, batch, _, _ = self.pool4(x, edge_index, None, batch)\n",
    "        x4 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "        print(f\"==============> x_post_conv4 : {x.shape} <===============\")\n",
    "        print(f\"==============> x4 : {x4.shape} <===============\")\n",
    "\n",
    "        x = x1 + x2 + x3 + x4\n",
    "        print(f\"==============> x_post_addition : {x.shape} <===============\")\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        print(f\"==============> x_post_Linear1 : {x.shape} <===============\")\n",
    "        x = F.relu(self.lin2(x))\n",
    "        print(f\"==============> x_post_Linear2 : {x.shape} <===============\")\n",
    "        y1 = F.log_softmax(self.lin3(x), dim=-1) # Final GNN output\n",
    "        y2 = torch.sigmoid(self.lin3(x)) # Classifier output\n",
    "        # print(f\"====================> y1 : {y1.shape}, y2 : {y2.shape} <====================\")\n",
    "\n",
    "        return y1, y2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad58cf55",
   "metadata": {},
   "source": [
    "### Training and Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9de8027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function for model training\n",
    "# def train(model,train_loader,device):\n",
    "#     model.train()\n",
    "\n",
    "#     loss_all = 0\n",
    "#     for data in train_loader:\n",
    "#         data = data.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         output, _ = model(data)\n",
    "#         loss = F.nll_loss(output, data.y)\n",
    "#         loss.backward()\n",
    "#         loss_all += data.num_graphs * loss.item()\n",
    "#         optimizer.step()\n",
    "#     return loss_all / len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f97596b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for model testing\n",
    "def test(model,loader):\n",
    "    model.eval()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    correct = 0.\n",
    "    loss = 0.   # edited by Ming with concern for further extension\n",
    "    pred_1 = list()\n",
    "    out_1 = np.array([])\n",
    "    gt_l = np.array([])\n",
    "    pred_bi = np.array([])\n",
    "    label = np.array([])\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out, out2 = model(data)\n",
    "#         print('out, out2 in test: ',out,out2)\n",
    "        pred = out.max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        loss += F.nll_loss(out, data.y,reduction='sum').item()\n",
    "        \n",
    "        pred_1.append(pred.cpu().detach().numpy())\n",
    "        out_1 = np.vstack([out_1, out2.cpu().detach().numpy()]) if out_1.size else out2.cpu().detach().numpy()\n",
    "        _tmp_label = data.y.cpu().detach().numpy()\n",
    "        for _label in _tmp_label:\n",
    "            if(_label == 0):\n",
    "                _label_3d = np.array([1, 0, 0])\n",
    "            elif(_label == 1):\n",
    "                _label_3d = np.array([0, 1, 0])\n",
    "            elif(_label == 2):\n",
    "                _label_3d = np.array([0, 0, 1])\n",
    "            gt_l = np.vstack([gt_l, _label_3d]) if gt_l.size else _label_3d\n",
    "        for _pred in pred:\n",
    "            if(_pred == 0):\n",
    "                _pred_bi = np.array([1, 0, 0])\n",
    "            if(_pred == 1):\n",
    "                _pred_bi = np.array([0, 1, 0])\n",
    "            if(_pred == 2):\n",
    "                _pred_bi = np.array([0, 0, 1])\n",
    "            pred_bi = np.vstack([pred_bi,_pred_bi]) if pred_bi.size else _pred_bi\n",
    "        label = np.hstack([label,_tmp_label]) if label.size else _tmp_label\n",
    "    # pred_1 = np.array(pred_1).reshape(pred_1)\n",
    "    return correct *1.0 / len(loader.dataset), loss / len(loader.dataset), pred_1, out_1, gt_l, label, pred_bi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af4f5f",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "59d23883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "learning_rate = 5e-4\n",
    "weight_decay = 1e-4\n",
    "nhid = 512\n",
    "pooling_ratio = 0.5\n",
    "epochs = 200\n",
    "num_class = 3\n",
    "# early_stopping = args.early_stopping\n",
    "num_layers = 4\n",
    "model_name = \"gintopk\"\n",
    "runs = 1\n",
    "fold = 5\n",
    "\n",
    "train_loss = np.zeros((1,epochs),dtype=float)\n",
    "val_acc = np.zeros((1,epochs))\n",
    "val_loss = np.zeros((1,epochs))\n",
    "val_pred = np.zeros(1)\n",
    "val_out = np.zeros((1,num_class))\n",
    "groud_truth = np.zeros((1,num_class))\n",
    "test_acc_c = np.zeros(1)\n",
    "test_loss_c = np.zeros(1)\n",
    "test_pred_c = np.zeros(1)\n",
    "test_out_c = np.zeros((1,num_class)) \n",
    "groud_truth_c = np.zeros((1,num_class))\n",
    "test_acc_p = np.zeros(1)\n",
    "min_loss = 1e10*np.ones(1)\n",
    "\n",
    "# early_stopping = epochs\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3690c85",
   "metadata": {},
   "source": [
    "### Data class and Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6d774fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a torch geometric dataset for each fold of trainig and validation sets\n",
    "\n",
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None, fold=None):\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # return ['edge_indices.csv', 'edge_attributes.csv', 'features.csv', 'labels.csv']\n",
    "        return ['fold_{fold}_edge_indices.csv', 'fold_{fold}_edge_attributes.csv', 'fold_{fold}_features.csv', 'fold_{fold}_labels.csv']\n",
    "            \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return 'data.pt'\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "    \n",
    "    def process(self):\n",
    "        ## load and preprocess data for Lung cancer\n",
    "        ld_edge_index = \"\"\n",
    "        ld_edge_attr = \"\"\n",
    "        ld_feature = \"\"\n",
    "        ld_label = \"\"\n",
    "        # ld_pid = \"\"\n",
    "\n",
    "        print(f'Looking into directory: {self.raw_dir} ...')\n",
    "        for _root, _dirs, _files in os.walk(self.raw_dir):\n",
    "            for _file in _files:\n",
    "                print(f'Loading File : {_file}')\n",
    "                if(\"edge_indices\" in _file):\n",
    "                    ld_edge_index = os.path.join(_root, _file)\n",
    "                if(\"edge_attributes\" in _file):\n",
    "                    ld_edge_attr = os.path.join(_root, _file)\n",
    "                elif(\"features\" in _file):\n",
    "                    ld_feature = os.path.join(_root, _file)\n",
    "                elif(\"labels\" in _file):\n",
    "                    ld_label = os.path.join(_root, _file)\n",
    "        \n",
    "        # load feature from .csv file without header\n",
    "        node_feature = pd.read_csv(ld_feature, skiprows=1, header=None, sep=',')\n",
    "        node_feature.index += 1\n",
    "        print('Node_Features :', node_feature.shape)\n",
    "        # load edge_attr from .csv file\n",
    "        edge_attr = pd.read_csv(ld_edge_attr, header=None, sep=',', names=['edge_attr'])\n",
    "        edge_attr.index += 1\n",
    "        print('Edge_attr :', edge_attr.shape)\n",
    "        # load edge_index from .csv files\n",
    "        edge_index = pd.read_csv(ld_edge_index, header=None, sep=',')\n",
    "        edge_index.index += 1\n",
    "        print('Edge_index :',edge_index.shape)\n",
    "        # load label from .csv file\n",
    "        label = pd.read_csv(ld_label, header=None, sep=',', names=['label'])\n",
    "        label.index += 1\n",
    "        print('Label :', label.shape)\n",
    "\n",
    "        data_list = list()\n",
    "        # Get values of the features\n",
    "        N_features = node_feature.values\n",
    "        print('*********', N_features.shape)\n",
    "        E_attrs = edge_attr.values\n",
    "        E_indices = edge_index.values\n",
    "        N_labels = label.values\n",
    "        # Convert DataFrames to tensors     \n",
    "        x = torch.tensor(N_features, dtype=torch.float)\n",
    "        edge_attrs = torch.tensor(E_attrs, dtype=torch.float)\n",
    "        edge_indices = torch.tensor(E_indices, dtype=torch.long)\n",
    "        edge_indices = edge_indices.t().contiguous()\n",
    "        N_labels = np.asarray([N_labels])\n",
    "        y = (torch.tensor(N_labels, dtype=torch.long))\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        num_node = x.shape[0]\n",
    "        num_feature = x.shape[1]\n",
    "        num_edge = edge_indices.shape[0]\n",
    "        \n",
    "        graph = Data(x=x, edge_index=edge_indices, edge_attr=edge_attrs, y=y)\n",
    "        data_list.append(graph)\n",
    "\n",
    "        # Apply the functions specified in pre_filter and pre_transform\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        # Store the processed data\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "#         return(data_list, num_feature, num_edge, num_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdc574a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking into directory: data\\folds\\training_folds\\fold1\\raw ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m run \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(runs):\n\u001b[0;32m      2\u001b[0m     \u001b[39m# for i in range(1,6):\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m):    \n\u001b[1;32m----> 4\u001b[0m         train_data \u001b[39m=\u001b[39m MyOwnDataset(root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdata/folds/training_folds/fold\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(i), pre_transform\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, transform\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, fold\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m      5\u001b[0m         val_data \u001b[39m=\u001b[39m MyOwnDataset(root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/folds/validation_folds/fold\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(i), pre_transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fold\u001b[39m=\u001b[39mi)\n\u001b[0;32m      6\u001b[0m         num_node, num_feature, num_edge \u001b[39m=\u001b[39m (train_data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mx)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], (train_data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mx)\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], (train_data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39medge_index)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[48], line 5\u001b[0m, in \u001b[0;36mMyOwnDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, fold)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pre_transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fold\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m----> 5\u001b[0m     \u001b[39msuper\u001b[39;49m(MyOwnDataset, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform)\n\u001b[0;32m      6\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_paths[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:55\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     48\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     49\u001b[0m     root: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     log: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     54\u001b[0m ):\n\u001b[1;32m---> 55\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter, log)\n\u001b[0;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\torch_geometric\\data\\dataset.py:94\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\torch_geometric\\data\\dataset.py:211\u001b[0m, in \u001b[0;36mDataset._process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[0;32m    210\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[1;32m--> 211\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[0;32m    213\u001b[0m path \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir, \u001b[39m'\u001b[39m\u001b[39mpre_transform.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    214\u001b[0m torch\u001b[39m.\u001b[39msave(_repr(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_transform), path)\n",
      "Cell \u001b[1;32mIn[48], line 42\u001b[0m, in \u001b[0;36mMyOwnDataset.process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m             ld_label \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(_root, _file)\n\u001b[0;32m     41\u001b[0m \u001b[39m# load feature from .csv file without header\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m node_feature \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(ld_feature, skiprows\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     43\u001b[0m node_feature\u001b[39m.\u001b[39mindex \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNode_Features :\u001b[39m\u001b[39m'\u001b[39m, node_feature\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "for run in range(runs):\n",
    "    # for i in range(1,6):\n",
    "    for i in range(1,2):    \n",
    "        train_data = MyOwnDataset(root='data/folds/training_folds/fold{}'.format(i), pre_transform=None, transform=None, fold=i)\n",
    "        val_data = MyOwnDataset(root='data/folds/validation_folds/fold{}'.format(i), pre_transform=None, transform=None, fold=i)\n",
    "        num_node, num_feature, num_edge = (train_data[0].x).shape[0], (train_data[0].x).shape[1], (train_data[0].edge_index).shape[0]\n",
    "    #     # see contents of the dataset\n",
    "    #     print('num_node:', num_node, ', num_feature:',num_feature, ', num_edge:', num_edge)\n",
    "    #     print(train_data[0])\n",
    "    #     print((train_data[0].edge_index.t()).shape)\n",
    "    #     print((train_data[0].edge_attr).shape)\n",
    "    #     print((train_data[0].x).shape)\n",
    "    #     print((train_data[0].y).shape)\n",
    "    #     for prop in train_data[0]:\n",
    "    #         print(prop)\n",
    "    #     print(val_data[0])\n",
    "    #     print((val_data[0].edge_index.t()).shape)\n",
    "    #     print((val_data[0].edge_attr).shape)\n",
    "    #     print((val_data[0].x).shape)\n",
    "    #     print((val_data[0].y).shape)\n",
    "    #     for prop in val_data[0]:\n",
    "    #         print(prop)\n",
    "        train_loader = DataLoader(train_data, batch_size=32, shuffle = True)\n",
    "        val_loader = DataLoader(val_data, batch_size=32, shuffle = True)\n",
    "\n",
    "        model = GINTopK(num_feature=num_feature, num_class=num_class, nhid=nhid).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "#         patience = 20\n",
    "#         early_stopping = EarlyStopping(patience=patience, verbose=True, path=\"{}/model_{}_fold{}_run{}.pth\".format(model_name, model_name, fold, run))\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            loss_all = 0\n",
    "            for i, data in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "#                 print('data in train: ', data)\n",
    "                out, out2 = model(data)\n",
    "                loss = F.nll_loss(out, data.y.squeeze())\n",
    "                loss.backward()\n",
    "                loss_all += data.num_graphs * loss.item()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            loss = loss_all / len(train_loader.dataset)   \n",
    "            train_loss[run,epoch] = loss\n",
    "            val_acc[run,epoch], val_loss[run, epoch], _, _, _, _, _ = test(model, val_loader)\n",
    "            print(\"Run: {:03d}, Epoch: {:03d}, Val loss: {:.5f}, Val acc: {:.5f}\".format(run+1,epoch+1,val_loss[run,epoch],val_acc[run,epoch]))\n",
    "            \n",
    "#             # early_stopping checks if the validation loss has decreased, if it has, it will make a checkpoint of the current model\n",
    "#             early_stopping(val_loss[run, epoch], model)\n",
    "        \n",
    "#             if early_stopping.early_stop:\n",
    "#                 print(\"Early stopping\")\n",
    "#                 break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89016f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking into directory: data\\folds\\training_folds\\fold1\\raw ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m):    \n\u001b[1;32m----> 2\u001b[0m         train_data \u001b[39m=\u001b[39m MyOwnDataset(root\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data/folds/training_folds/fold\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m, pre_transform\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, transform\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, fold\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m      3\u001b[0m         num_node, num_feature, num_edge \u001b[39m=\u001b[39m (train_data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mx)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], (train_data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mx)\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], (train_data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39medge_index)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m         \u001b[39m# see contents of the dataset\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[48], line 5\u001b[0m, in \u001b[0;36mMyOwnDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, fold)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pre_transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fold\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m----> 5\u001b[0m     \u001b[39msuper\u001b[39;49m(MyOwnDataset, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform)\n\u001b[0;32m      6\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_paths[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:55\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     48\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     49\u001b[0m     root: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     log: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     54\u001b[0m ):\n\u001b[1;32m---> 55\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter, log)\n\u001b[0;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\torch_geometric\\data\\dataset.py:94\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\torch_geometric\\data\\dataset.py:211\u001b[0m, in \u001b[0;36mDataset._process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[0;32m    210\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[1;32m--> 211\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[0;32m    213\u001b[0m path \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir, \u001b[39m'\u001b[39m\u001b[39mpre_transform.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    214\u001b[0m torch\u001b[39m.\u001b[39msave(_repr(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_transform), path)\n",
      "Cell \u001b[1;32mIn[48], line 42\u001b[0m, in \u001b[0;36mMyOwnDataset.process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m             ld_label \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(_root, _file)\n\u001b[0;32m     41\u001b[0m \u001b[39m# load feature from .csv file without header\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m node_feature \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(ld_feature, skiprows\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     43\u001b[0m node_feature\u001b[39m.\u001b[39mindex \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNode_Features :\u001b[39m\u001b[39m'\u001b[39m, node_feature\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "for i in range(1,2):    \n",
    "        train_data = MyOwnDataset(root=f'./data/folds/training_folds/fold{i}', pre_transform=None, transform=None, fold=i)\n",
    "        num_node, num_feature, num_edge = (train_data[0].x).shape[0], (train_data[0].x).shape[1], (train_data[0].edge_index).shape[0]\n",
    "        # see contents of the dataset\n",
    "        print('num_node:', num_node, ', num_feature:',num_feature, ', num_edge:', num_edge)\n",
    "        print(train_data[0])\n",
    "        print('edge_index:',(train_data[0].edge_index).shape)\n",
    "        print('edge_attr',(train_data[0].edge_attr).shape)\n",
    "        print('x:',(train_data[0].x).shape)\n",
    "        print('y:',(train_data[0].y).shape)\n",
    "        for prop in train_data[0]:\n",
    "            print(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a87f0e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking into directory: data\\folds\\validation_folds\\fold1\\raw ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Let's create data object for validation folds\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m6\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     dataset \u001b[39m=\u001b[39m MyOwnDataset(root\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data/folds/validation_folds/fold\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m, pre_transform\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, transform\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, fold\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m      4\u001b[0m     \u001b[39m# see contents of the dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(dataset[\u001b[39m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[48], line 5\u001b[0m, in \u001b[0;36mMyOwnDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, fold)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pre_transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, fold\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m----> 5\u001b[0m     \u001b[39msuper\u001b[39;49m(MyOwnDataset, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform)\n\u001b[0;32m      6\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_paths[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:55\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     48\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     49\u001b[0m     root: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m     log: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     54\u001b[0m ):\n\u001b[1;32m---> 55\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter, log)\n\u001b[0;32m     56\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\torch_geometric\\data\\dataset.py:94\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\torch_geometric\\data\\dataset.py:211\u001b[0m, in \u001b[0;36mDataset._process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[0;32m    210\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[1;32m--> 211\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[0;32m    213\u001b[0m path \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir, \u001b[39m'\u001b[39m\u001b[39mpre_transform.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    214\u001b[0m torch\u001b[39m.\u001b[39msave(_repr(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_transform), path)\n",
      "Cell \u001b[1;32mIn[48], line 42\u001b[0m, in \u001b[0;36mMyOwnDataset.process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m             ld_label \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(_root, _file)\n\u001b[0;32m     41\u001b[0m \u001b[39m# load feature from .csv file without header\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m node_feature \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(ld_feature, skiprows\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     43\u001b[0m node_feature\u001b[39m.\u001b[39mindex \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     44\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNode_Features :\u001b[39m\u001b[39m'\u001b[39m, node_feature\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\aakas\\miniconda3\\envs\\graph\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "# Let's create data object for validation folds\n",
    "for i in range(1,6):\n",
    "    dataset = MyOwnDataset(root=f'./data/folds/validation_folds/fold{i}', pre_transform=None, transform=None, fold=i)\n",
    "    # see contents of the dataset\n",
    "    print(dataset[0])\n",
    "    print((dataset[0].edge_index.t()).shape)\n",
    "    print((dataset[0].edge_attr).shape)\n",
    "    print((dataset[0].x).shape)\n",
    "    print((dataset[0].y.squeeze()).shape)\n",
    "    for prop in dataset[0]:\n",
    "        print(prop)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa86eb98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb286a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2d314126d118f6897c7fbd822713dbfec7129994ecb68079fe10a3e787a008c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
